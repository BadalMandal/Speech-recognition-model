{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6763b3-2a49-4513-bc3a-ade3c58f3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b74a00-cfb4-4de9-89a7-2a9f46957bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_audio_features(audio_file, coeff_count=20):\n",
    "    signal, rate = librosa.load(audio_file, sr=None)\n",
    "    coefficients = librosa.feature.mfcc(y=signal, sr=rate, n_mfcc=coeff_count)\n",
    "    delta = librosa.feature.delta(coefficients)\n",
    "    delta2 = librosa.feature.delta(coefficients, order=2)\n",
    "    merged_features = np.vstack((coefficients, delta, delta2))\n",
    "    return np.hstack([np.mean(merged_features, axis=1), np.std(merged_features, axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118708fd-92b8-4b90-930d-4b14d71ef5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_voice_data(data_root):\n",
    "    voice_features, speaker_ids = [], []\n",
    "    for speaker_dir in os.listdir(data_root):\n",
    "        dir_path = os.path.join(data_root, speaker_dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for audio_file in os.listdir(dir_path):\n",
    "                if audio_file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(dir_path, audio_file)\n",
    "                    mfcc_data = compute_audio_features(file_path)\n",
    "                    voice_features.append(mfcc_data)\n",
    "                    speaker_ids.append(speaker_dir)\n",
    "    return np.array(voice_features), np.array(speaker_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ccbb399-f27e-42b1-a2ee-405175f3b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_voice_data(data_root):\n",
    "    for speaker_dir in os.listdir(data_root):\n",
    "        dir_path = os.path.join(data_root, speaker_dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for audio_file in os.listdir(dir_path):\n",
    "                if audio_file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(dir_path, audio_file)\n",
    "                    signal, rate = librosa.load(file_path, sr=None)\n",
    "                    coefficients = librosa.feature.mfcc(y=signal, sr=rate, n_mfcc=20)\n",
    "                    plt.figure(figsize=(10, 4))\n",
    "                    librosa.display.specshow(coefficients, x_axis='time')\n",
    "                    plt.colorbar()\n",
    "                    plt.title(f'MFCC Spectrogram: {speaker_dir} - {audio_file}')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e9b100-3e91-484a-812d-02ea15e83f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_data_path = \"Data\\\\Input\\\\Training\"\n",
    "features, labels = collect_voice_data(voice_data_path)\n",
    "normalizer = StandardScaler()\n",
    "normalized_Dimension = normalizer.fit_transform(features)\n",
    "\n",
    "cross_validator = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "performance_scores = []\n",
    "ignore_threshold = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39651b13-1585-46f2-94f7-529dfbb5c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in cross_validator.split(normalized_Dimension):\n",
    "    X_train, X_test = normalized_Dimension[train_idx], normalized_Dimension[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    gmm_models_of_entry = {}\n",
    "    for speaker in np.unique(y_train):\n",
    "        speaker_data = X_train[y_train == speaker]\n",
    "        data_points = speaker_data.shape[0]\n",
    "        mixture_count = min(32, max(2, data_points // 2))\n",
    "        gmm = GaussianMixture(n_components=mixture_count, covariance_type='full', max_iter=200, random_state=42)\n",
    "        gmm.fit(speaker_data)\n",
    "        gmm_models_of_entry[speaker] = gmm\n",
    "    correct_count = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_sample = X_test[i].reshape(1, -1)\n",
    "        true_speaker = y_test[i]\n",
    "        best_score = float('-inf')\n",
    "        identified_speaker = None\n",
    "        for speaker, model in gmm_models_of_entry.items():\n",
    "            likelihood = model.score(test_sample)\n",
    "            #print(f\"Likelihood for {speaker}: {likelihood}\")\n",
    "            if likelihood > best_score:\n",
    "                best_score = likelihood\n",
    "                identified_speaker = speaker\n",
    "        if ignore_threshold or best_score > -50:\n",
    "            if identified_speaker == true_speaker:\n",
    "                correct_count += 1\n",
    "    fold_accuracy = correct_count / len(X_test)\n",
    "    performance_scores.append(fold_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd74dcd-6497-4b8a-93d1-2bedd8d05ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_speaker(audio_sample, model_dict, feature_scaler, score_threshold=-50):\n",
    "    sample_features = compute_audio_features(audio_sample)\n",
    "    normalized_features = feature_scaler.transform([sample_features])\n",
    "    highest = float('-inf')\n",
    "    probable_voice = None\n",
    "    for speaker, model in model_dict.items():\n",
    "        likelihood = model.score(normalized_features)\n",
    "        print(f\"Likelihood for {speaker}: {likelihood}\")\n",
    "        if likelihood > highest:\n",
    "            probable_voice = speaker\n",
    "            highest = likelihood\n",
    "    return probable_voice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64986211-615f-40e0-a37c-d3c679919cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = np.mean(performance_scores)\n",
    "print(f\"Average Cross-Validation Accuracy: {average_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a74eb-63de-4160-b0fb-23d0b5331675",
   "metadata": {},
   "source": [
    "You can change the path for different test sample and it working Quite good on that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc1dfea-7982-46c8-b39f-432165a30fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood for Abhay-001: -112674144.86172944\n",
      "Likelihood for Eknath-002: -107693945.97117543\n",
      "Likelihood for Rg-003: -109217035.22017416\n",
      "Likelihood for Rishika-004: -115834562.05809252\n",
      "Likelihood for ShivamY-006: -58678419.400855795\n",
      "Likelihood for Vaibhav-005: -93513428.93072116\n",
      "Recognized Speaker: ShivamY-006\n"
     ]
    }
   ],
   "source": [
    "test_path = \"Data\\\\Input\\\\Test\\\\ShivamY_audio2.wav\"\n",
    "recognized_speaker = identify_speaker(test_path, gmm_models_of_entry, normalizer)\n",
    "print(f\"Recognized Speaker: {recognized_speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dffb4b-673d-4147-8c80-1cd0c7da3ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
